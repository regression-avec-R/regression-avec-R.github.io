<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Régression avec R - 5 Inférence dans le modèle gaussien</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../correction/chap6.html" rel="next">
<link href="../correction/chap4.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Pas de résultats",
    "search-matching-documents-text": "documents trouvés",
    "search-copy-link-title": "Copier le lien vers la recherche",
    "search-hide-matches-text": "Cacher les correspondances additionnelles",
    "search-more-match-text": "correspondance de plus dans ce document",
    "search-more-matches-text": "correspondances de plus dans ce document",
    "search-clear-button-title": "Effacer",
    "search-detached-cancel-button-title": "Annuler",
    "search-submit-button-title": "Envoyer"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Correction des exercices</li><li class="breadcrumb-item"><a href="../correction/chap5.html">II Inférence</a></li><li class="breadcrumb-item"><a href="../correction/chap5.html">5 Inférence dans le modèle gaussien</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Recherche" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Régression avec R</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Basculer en mode lecteur">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Recherche"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3ème édition</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Jeux de données</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Codes R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">I Introduction au modèle linéaire</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 Régression simple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 La régression linéaire multiple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 Validation du modèle</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">II Inférence</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 Inférence dans le modèle Gaussien</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6 Variables qualitatives : ANCOVA et ANOVA</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">III Réduction de dimension</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7 Choix de variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8 Régularisation des moindres carrés : Ridge, Lasso et elastic net</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9 Régression sur composantes : PCR et PLS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10 Comparaison des différentes méthodes, étude de cas réels</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">IV Le modèle linéairé généralisé</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11 Régression logistique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12 Régression de Poisson</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13 Régularisation de la vraisemblance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15 Données déséquilibrées</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">V Introduction à la régression non paramétrique</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16 Introduction à la régression spline</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17 Estimateurs à noyau et <span class="math inline">\(k\)</span> plus proches voisins</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Correction des exercices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false">
 <span class="menu-text">I Introduction au modèle linéaire</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 La régression linéaire simple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 La régression linéaire multiple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 Validation du modèle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 Extensions : non-inversibilité et (ou) erreurs corrélées</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true">
 <span class="menu-text">II Inférence</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap5.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">5 Inférence dans le modèle gaussien</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6 Variables qualitatives : ANCOVA et ANOVA</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false">
 <span class="menu-text">III Réduction de dimension</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7 Choix de variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8 Régularisation des moindre carrés : Ridge, Lasso et elastic net</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9 Régression sur composantes : PCR et PLS</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false">
 <span class="menu-text">IV Le modèle linéairé généralisé</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11 Régression logistique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12 Régression de Poisson</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13 Régularisation de la vraisemblance</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false">
 <span class="menu-text">V Introduction à la régression non paramétrique</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17 Estimateurs à noyau et <span class="math inline">\(k\)</span> plus proches voisins</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">5 Inférence dans le modèle gaussien</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell">

</div>
<div id="exr-5-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 1 (Questions de cours) </strong></span>A, C, A, B, B.</p>
</div>
<div id="exr-5-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 2 (Théorème 5.1) </strong></span>L’IC (i) découle de la propriété (i) de la proposition 5.3. La propriété (ii) donnant un IC pour <span class="math inline">\(\sigma^2\)</span> découle de la loi de <span class="math inline">\(\hat \sigma^2\)</span>. Enfin, la propriété (iii) est une conséquence de la loi obtenue propriété (ii) de la proposition 5.3.</p>
</div>
<div id="exr-5-3" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 3 (Test et <span class="math inline">\(R^2\)</span>) </strong></span>En utilisant l’orthogonalité des sous-espaces (figure 5.3 page 99) et le théorème de Pythagore, nous avons <span class="math display">\[\begin{eqnarray*}
\|\hat Y_0-\hat Y\|^2 &amp;=&amp; \|\hat \varepsilon_0\|^2- \| \hat \varepsilon\|^2.
\end{eqnarray*}\]</span> Nous pouvons le démontrer de la manière suivante : <span class="math display">\[\begin{eqnarray*}
\|\hat Y_0-\hat Y\|^2 &amp;=&amp; \|\hat Y_0-Y+Y-\hat Y\|^2\\
&amp;=&amp; \|\hat \varepsilon_0\|^2+ \| \hat \varepsilon\|^2
+2\langle \hat Y_0-Y,Y-\hat Y\rangle\\
&amp;=&amp; \|\hat \varepsilon_0\|^2+ \| \hat \varepsilon\|^2
-2\langle Y-\hat Y_0,Y-\hat Y\rangle\\
&amp;=&amp; \|\hat \varepsilon_0\|^2+ \| \hat \varepsilon\|^2
-2\langle P_{X_0^\perp}Y,P_{X^\perp}Y\rangle\\
&amp;=&amp; \|\hat \varepsilon_0\|^2+ \| \hat \varepsilon\|^2
-2\langle (P_{X^\perp}+P_{X})P_{X_0^\perp}Y,P_{X^\perp}Y\rangle.
\end{eqnarray*}\]</span> Or <span class="math inline">\(\Im(X_0) \subset \Im(X)\)</span>, nous avons donc <span class="math inline">\(P_{X^\perp}P_{X_0^\perp}=P_{X^\perp}\)</span>. De plus, <span class="math inline">\(\hat \varepsilon=P_{X^\perp}Y\)</span>, cela donne <span class="math display">\[\begin{eqnarray*}
\langle (P_{X^\perp}+P_{X})P_{X_0^\perp}Y,P_{X^\perp}Y\rangle &amp;=&amp;
\langle P_{X^\perp}Y,P_{X^\perp}Y\rangle
+\langle P_{X}P_{X_0^\perp}Y,P_{X^\perp}Y\rangle \\
&amp;=&amp; \|\hat \varepsilon\|^2 + 0.
\end{eqnarray*}\]</span> Le résultat est démontré, revenons à la statistique de test. Introduisons les différentes écritures du <span class="math inline">\(\mathop{\mathrm{R^2}}\)</span> <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{R^2}}2 = \frac{\|\hat Y - \bar Y\|^2}{\|Y - \bar Y\|^2}=1 -
\frac{\|\hat \varepsilon\|^2}{\|Y - \bar Y\|^2}.
\end{eqnarray*}\]</span> La statistique de test vaut <span class="math display">\[\begin{eqnarray*}
F&amp;=&amp;\frac{\|\hat \varepsilon_0\|^2- \| \hat \varepsilon\|^2}
{\| Y-\hat Y\|^2}\frac{n-p}{p-p_0}\\
&amp;=&amp;\frac{\|\hat \varepsilon_0\|^2/\|Y-\bar Y\|^2-
\| \hat \varepsilon\|^2/\|Y-\bar Y\|^2}
{\| Y-\hat Y\|^2/\|Y-\bar Y\|^2}\frac{n-p}{p-p_0},
\end{eqnarray*}\]</span> nous obtenons <span class="math display">\[\begin{eqnarray*}
F&amp;=&amp;\frac{\mathop{\mathrm{R^2}}-\mathop{\mathrm{R^2_0}}}{1-\mathop{\mathrm{R^2}}}\frac{n-p}{p-p_0},
\end{eqnarray*}\]</span> soit le résultat annoncé. Cette dernière quantité est toujours positive car <span class="math inline">\(\mathop{\mathrm{R^2_0}}\leq \mathop{\mathrm{R^2}}\)</span> et nous avons là un moyen de tester des modèles emboîtés <em>via</em> le coefficient de détermination.</p>
</div>
<div id="exr-5-4" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 4 (Test et <span class="math inline">\(R^2\)</span> et constante dans le modèle) </strong></span>à corriger ;).</p>
</div>
<div id="exr-5-5" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 5 (Ozone) </strong></span>&nbsp;</p>
<ol type="1">
<li><p>Les résultats sont dans l’ordre <span class="math display">\[\begin{eqnarray*}
6.2, 0.8, 6.66, -1.5, -1, 50, 5, 124.
\end{eqnarray*}\]</span></p></li>
<li><p>La statistique de test de nullité du paramètre se trouve dans la troisième colonne, nous conservons <span class="math inline">\({\mathrm{H_0}}\)</span> pour les paramètres associés à Ne9 et Ne12, et la rejetons pour les autres.</p></li>
<li><p>La statistique de test de nullité simultanée des paramètres autres que la constante vaut 50. Nous rejetons <span class="math inline">\({\mathrm{H_0}}\)</span>.</p></li>
<li><p>Nous connaissons <span class="math display">\[\begin{align*}
\hat y^{p}_{n+1} &amp;= x'_{n+1}\hat \beta,\\
x'_{n+1}&amp;=(1, 10, 20, 0, 0, 1)\\
\hat \beta&amp;=(62, -4, 5, -1.5, -0.5, 0.8)'
\end{align*}\]</span> et donc la prévision est <span class="math inline">\(\hat y^{p}_{n+1} =122.8\)</span>. Pour l’intervalle de confiance il nous faut <span class="math inline">\(\hat\sigma=16\)</span> mais aussi la matrice <span class="math inline">\(X'X\)</span> (donc toutes les données) ce que nous n’avons pas ici. On ne peut donc faire d’intervalle de confiance.</p></li>
<li><p>Nous sommes en présence de modèles emboîtés, nous pouvons appliquer la formule adaptée (voir l’exercice précédent) : <span class="math display">\[\begin{eqnarray*}
F&amp;=&amp; \frac{\mathop{\mathrm{R^2}}2-\mathop{\mathrm{R^2_0}}2}{1-\mathop{\mathrm{R^2}}2}\frac{n-p}{p-p_0}\\
&amp;=&amp; \frac{0.66-0.5}{1-0.66}\frac{124}{2}= 29.
\end{eqnarray*}\]</span> Nous conservons <span class="math inline">\({\mathrm{H_0}}\)</span>, c’est-à-dire le modèle le plus simple.</p></li>
</ol>
</div>
<div id="exr-5-6" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 6 (Équivalence du test T et du test F) </strong></span>Récrivons la statistique de test <span class="math inline">\(F\)</span>, en se rappelant que <span class="math inline">\(X_0\)</span> est la matrice <span class="math inline">\(X\)</span> privée de sa <span class="math inline">\(j^e\)</span> colonne, celle correspondant au coefficient que l’on teste : <span class="math display">\[\begin{eqnarray*}
F&amp;=&amp;\frac{\|X\hat \beta-P_{X_0}X\hat \beta\|^2}{\hat \sigma^2}
  =\frac{\|X_j\hat \beta_j-\hat \beta_jP_{X_0}X_j\|^2}{\hat \sigma^2}
=\frac{\hat\beta_j^2}{\hat \sigma^2}X_j'(I-P_{X_0})X_j.
\end{eqnarray*}\]</span> Récrivons maintenant le carré de la statistique <span class="math inline">\(T\)</span> en explicitant <span class="math inline">\(\hat  \sigma^2_{\hat \beta_j}\)</span> : <span class="math display">\[\begin{eqnarray*}
T^2&amp;=&amp;\frac{\hat \beta_j^2}{\hat \sigma^2 [(X'X)^{-1}]_{jj}},
\end{eqnarray*}\]</span> où <span class="math inline">\([(X'X)^{-1}]_{jj}\)</span> est le <span class="math inline">\(j^e\)</span> élément diagonal de la matrice <span class="math inline">\((X'X)^{-1}\)</span>. Afin de calculer ce terme, nous utilisons la formule permettant d’obtenir l’inverse d’une matrice bloc, formule donnée en annexe A.2 page 416. Pour appliquer facilement cette formule, en changeant l’ordre des variables, la matrice <span class="math inline">\(X\)</span> devient <span class="math inline">\((X_0|X_j)\)</span> et <span class="math inline">\(X'X\)</span> s’écrit alors <span class="math display">\[\begin{eqnarray*}
X'X&amp;=&amp;\left(
\begin{array}{c|c}
X'_0X_0&amp;X'_0X_j\\\hline
X'_jX_0&amp;X'_jX_j
\end{array}\right).
\end{eqnarray*}\]</span> Son inverse, en utilisant la formule d’inverse de matrice bloc, est <span class="math display">\[\begin{eqnarray*}
[(X'X)^{-1}]_{jj}&amp;=&amp;\left(X'_jX_j-X'_jX_0(X'_0X_0)^{-1}X'_0X_j\right)^{-1}
=\left(X_j'(I-P_{X_0})X_j\right)^{-1}.
\end{eqnarray*}\]</span> Nous avons donc <span class="math inline">\(T^2=F\)</span>. Au niveau des lois, l’égalité est aussi valable et nous avons que le carré d’un Student à <span class="math inline">\((n-p)\)</span> ddl est une loi de Fisher à <span class="math inline">\((1,n-p)\)</span> ddl. Bien entendu, le quantile <span class="math inline">\((1-\alpha)\)</span> d’une loi de Fisher correspond au quantile <span class="math inline">\(1-\alpha/2\)</span> d’une loi de Student. La loi <span class="math inline">\(\mathcal{T}\)</span> est symétrique autour de 0 et donc, lorsqu’elle est élevée au carré, les valeurs plus faibles que <span class="math inline">\(t_{n-p}(\alpha/2)\)</span>, qui ont une probabilité sous <span class="math inline">\({\mathrm{H_0}}\)</span> de <span class="math inline">\(\alpha/2\)</span> d’apparaître, et celles plus fortes que <span class="math inline">\(t_{n-p}(1-\alpha/2)\)</span>, qui ont une probabilité sous <span class="math inline">\({\mathrm{H_0}}\)</span> de <span class="math inline">\(\alpha/2\)</span> d’apparaître, deviennent toutes plus grandes que <span class="math inline">\(t^2_{n-p}(1-\alpha/2)\)</span>. La probabilité que ces valeurs dépassent ce seuil sous <span class="math inline">\({\mathrm{H_0}}\)</span> est de <span class="math inline">\(\alpha\)</span> et correspond donc bien par définition à <span class="math inline">\(f_{1,n-p}(1-\alpha)\)</span>.</p>
</div>
<div id="exr-5-7" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 7 (Équivalence du test F et du test de VM) </strong></span>Nous avons noté la vraisemblance en début du chapitre par <span class="math display">\[\begin{eqnarray*}
\mathcal{L}(Y,\beta,\sigma^2) &amp;=&amp; \prod_{i=1}^n f_{Y}(y_i)
= \left(\frac{1}{2\pi\sigma^2}\right)^{n/2}\exp{\left[-\frac{1}{2 \sigma^2}
\sum_{i=1}^n \left(y_i- \sum_{j=1}^p\beta_jx_{ij}\right)^2\right]}\\
&amp;=&amp; \left(\frac{1}{2\pi\sigma^2}\right)^{n/2}\exp{\left[-\frac{1}{2 \sigma^2}
\|Y-X\beta\|^2\right]}.
\end{eqnarray*}\]</span> Cette vraisemblance est maximale lorsque <span class="math inline">\(\hat \beta\)</span> est l’estimateur des MC et que <span class="math inline">\(\hat \sigma^2 = \|Y-X\hat \beta\|^2/n\)</span>. Nous avons alors <span class="math display">\[\begin{eqnarray*}
\max_{\beta,\sigma^2} \mathcal{L}(Y,\beta,\sigma^2)&amp;=&amp;
\left(\frac{n}{2\pi\|Y-X\hat \beta\|^2 }\right)^{n/2}\exp{\left(-\frac{n}{2}\right)}\\
&amp;=&amp;\left(\frac{n}{2\pi \mathop{\mathrm{SCR}}}\right)^{n/2}\exp{\left(-\frac{n}{2}\right)}
=\mathcal{L}(Y,\hat \beta,\hat \sigma^2),
\end{eqnarray*}\]</span> où <span class="math inline">\(\mathop{\mathrm{SCR}}=\|Y-X\hat \beta\|^2\)</span>.</p>
<p>Sous l’hypothèse <span class="math inline">\({\mathrm{H_0}}\)</span> nous obtenons de façon évidente le résultat suivant : <span class="math display">\[\begin{eqnarray*}
\max_{\beta,\sigma^2} \mathcal{L}_0(Y,\beta_0,\sigma^2)
=\left(\frac{n}{2\pi \mathop{\mathrm{SCR}}_0}\right)^{n/2}\exp{\left(-\frac{n}{2}\right)}
=\mathcal{L}_0(Y,\hat \beta_0,\hat \sigma^2_0),
\end{eqnarray*}\]</span> où <span class="math inline">\(\mathop{\mathrm{SCR}}_0\)</span> correspond à la somme des carrés résiduels sous <span class="math inline">\({\mathrm{H_0}}\)</span>, c’est-à-dire <span class="math inline">\(\mathop{\mathrm{SCR}}_0=\|Y-X_0\hat \beta_0\|^2\)</span>. On définit le test du rapport de vraisemblance maximale (VM) par la région critique suivante : <span class="math display">\[\begin{eqnarray*}
\mathcal{D}_\alpha = \left\{
Y \in \mathbb R^n : \lambda=\frac{\mathcal{L}_0(Y,\hat \beta_0,\hat \sigma^2)}
{\mathcal{L}(Y,\hat \beta,\hat \sigma^2)} &lt; \lambda_0
\right\}.
\end{eqnarray*}\]</span> La statistique du rapport de vraisemblance maximale vaut ici <span class="math display">\[\begin{eqnarray*}
\lambda = \left(\frac{\mathop{\mathrm{SCR}}}{\mathop{\mathrm{SCR}}_0}\right)^{n/2} =
\left(\frac{\mathop{\mathrm{SCR}}_0}{\mathop{\mathrm{SCR}}}\right)^{-n/2}.
\end{eqnarray*}\]</span> Le test du rapport de VM rejette <span class="math inline">\({\mathrm{H_0}}\)</span> lorsque la statistique <span class="math inline">\(\lambda\)</span> est inférieure à une valeur <span class="math inline">\(\lambda_0\)</span> définie de façon à avoir le niveau du test égal à <span class="math inline">\(\alpha\)</span>. Le problème qui reste à étudier est de connaître la distribution (au moins sous <span class="math inline">\({\mathrm{H_0}}\)</span>) de <span class="math inline">\(\lambda\)</span>. Définissons, pour <span class="math inline">\(\lambda\)</span> positif, la fonction bijective <span class="math inline">\(g\)</span> suivante : <span class="math display">\[\begin{eqnarray*}
g(\lambda) = \lambda^{-2/n}-1.
\end{eqnarray*}\]</span> La fonction <span class="math inline">\(g\)</span> est décroissante (sa dérivée est toujours négative), donc <span class="math inline">\(\lambda&lt;\lambda_0\)</span> si et seulement si <span class="math inline">\(g(\lambda)&gt;g(\lambda_0)\)</span>. Cette fonction <span class="math inline">\(g\)</span> va nous permettre de nous ramener à des statistiques dont la loi est connue. Nous avons alors <span class="math display">\[\begin{eqnarray*}
g(\lambda)&amp;&gt;&amp;g(\lambda_0)\\
\frac{\mathop{\mathrm{SCR}}_0-\mathop{\mathrm{SCR}}}{\mathop{\mathrm{SCR}}}&amp;&gt;&amp;g(\lambda_0)\\
\frac{n-p}{p-p_0}\frac{\mathop{\mathrm{SCR}}_0-\mathop{\mathrm{SCR}}}{\mathop{\mathrm{SCR}}}&amp;&gt;&amp;f_0
\end{eqnarray*}\]</span> où <span class="math inline">\(f_0\)</span> est déterminée par <span class="math display">\[\begin{eqnarray*}
P_{{\mathrm{H_0}}}\left(\frac{n-p}{p-p_0}\frac{\mathop{\mathrm{SCR}}_0-\mathop{\mathrm{SCR}}}{\mathop{\mathrm{SCR}}}&gt;f_0
\right)=\alpha,
\end{eqnarray*}\]</span> avec la loi de cette statistique qui est une loi <span class="math inline">\(\mathcal{F}_{p-p_0,n-p}\)</span> (cf.~section précédente). Le test du rapport de VM est donc équivalent au test qui rejette <span class="math inline">\({\mathrm{H_0}}\)</span> lorsque la statistique <span class="math display">\[\begin{eqnarray*}
F=\frac{n-p}{p-p_0}\frac{\mathop{\mathrm{SCR}}_0-\mathop{\mathrm{SCR}}}{\mathop{\mathrm{SCR}}}
\end{eqnarray*}\]</span> est supérieure à <span class="math inline">\(f_0\)</span>, où <span class="math inline">\(f_0\)</span> est la valeur du fractile <span class="math inline">\(\alpha\)</span> de la loi de Fisher à <span class="math inline">\((p-p_0,n-p)\)</span> degrés de liberté.</p>
</div>
<div id="exr-5-8" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 8 (Test de Fisher pour une hypothèse linéaire quelconque) </strong></span>Nous pouvons toujours traduire l’hypothèse <span class="math inline">\({\mathrm{H_0}}\)</span> : <span class="math inline">\(R\beta=r\)</span> en terme de sous-espace de <span class="math inline">\(\mathcal M_X\)</span>. Lorsque <span class="math inline">\(r=0\)</span>, nous avons un sous-espace vectoriel de <span class="math inline">\(\mathcal M_X\)</span> et lorsque <span class="math inline">\(r\neq 0\)</span> nous avons un sous-espace affine de <span class="math inline">\(\mathcal M_X\)</span>. Dans les deux cas, nous noterons ce sous-espace <span class="math inline">\(\mathcal M_0\)</span> et <span class="math inline">\(\mathcal M_0 \subset \mathcal M_X\)</span>. Cependant nous ne pourrons plus le visualiser facilement comme nous l’avons fait précédemment avec <span class="math inline">\(\mathcal M_{X_0}\)</span> où nous avions enlevé des colonnes à la matrice <span class="math inline">\(X\)</span>. Nous allons décomposer l’espace <span class="math inline">\(\mathcal M_X\)</span> en deux sous-espaces orthogonaux <span class="math display">\[\begin{eqnarray*}
\mathcal M_X = \mathcal M_0 \stackrel{\perp}{\oplus} ( \mathcal M_0^\perp \cap \mathcal M_X ).
\end{eqnarray*}\]</span> Sous <span class="math inline">\({\mathrm{H_0}}\)</span>, l’estimation des moindres carrés donne <span class="math inline">\(\hat Y_0\)</span> projection orthogonale de <span class="math inline">\(Y\)</span> sur <span class="math inline">\(\mathcal M_0\)</span> et nous appliquons la même démarche pour construire la statistique de test. La démonstration est donc la même que celle du théorème 5.2. C’est-à-dire que nous regardons si <span class="math inline">\(\hat Y_0\)</span> est proche de <span class="math inline">\(\hat Y\)</span> et nous avons donc <span class="math display">\[\begin{eqnarray*}
F&amp;=&amp;\frac{\|\hat Y -\hat Y_0\|^2/\dim(\mathcal M_0^{\perp}  \cap \mathcal M_X)}{\|Y - \hat Y\|^2/
\dim(\mathcal M_{X^{\perp}})}\\
&amp;=&amp;\frac{n-p}{q} \frac{\|Y-\hat Y_0\|^2-\|Y-\hat Y\|^2}{ \|Y-\hat Y\|^2}\\
&amp;=&amp; \frac{n-p}{q}\frac{\mathop{\mathrm{SCR}}_0-\mathop{\mathrm{SCR}}}{\mathop{\mathrm{SCR}}}\sim \mathcal{F}_{q,n-p}.
\end{eqnarray*}\]</span> Le problème du test réside dans le calcul de <span class="math inline">\(\hat Y_0\)</span>. Dans la partie précédente, il était facile de calculer <span class="math inline">\(\hat Y_0\)</span> car nous avions la forme explicite du projecteur sur <span class="math inline">\(\mathcal M_0\)</span>. Une première façon de procéder revient à trouver la forme du projecteur sur <span class="math inline">\(\mathcal M_0\)</span>. Une autre façon de faire est de récrire le problème de minimisation sous la contrainte <span class="math inline">\(R\beta=r\)</span>. Ces deux manières d’opérer sont présentées en détail dans la correction de l’exercice 2.13. Dans tous les cas l’estimateur des MC contraints par <span class="math inline">\(R\beta=r\)</span> est défini par <span class="math display">\[\begin{eqnarray*}
\hat \beta_0&amp;=&amp;\hat \beta + (X'X)^{-1}R'[R(X'X)^{-1}R']^{-1}(r-R\hat \beta).
\end{eqnarray*}\]</span></p>
</div>
<div id="exr-5-9" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 9 (Généralisation de la régression ridge) </strong></span>Soit la fonction à minimiser <span class="math display">\[\begin{align*}
    R(\beta)&amp;=\|Y-X\beta\|^2 -\sum_{j=1}^{p}\delta_j(\beta_j^2) \\
    &amp;= (Y-X\beta)'(Y-X\beta) - \beta' \Delta \beta
  \end{align*}\]</span> avec <span class="math inline">\(\delta_{1}, \dotsc, \delta_{p}\)</span> des réels positifs ou nuls.</p>
<p>Sachant que <span class="math inline">\(\frac{\partial \beta' A\beta}{\partial \beta}=2A\beta\)</span> (avec <span class="math inline">\(A\)</span> symétrique) et que <span class="math inline">\(\frac{\partial X\beta}{\partial \beta}=X'\)</span> nous avons la dérivée partielle suivante <span class="math display">\[\begin{align*}
    \frac{\partial R}{\partial \beta}&amp;=-2X'(Y-X\beta)  + 2\Delta \beta
  \end{align*}\]</span> En annulant cette dérivée nous avons <span class="math display">\[\begin{align*}
    -2X'(Y-X\hat\beta_{\mathrm{RG}}) + 2\Delta \hat\beta_{\mathrm{RG}}&amp;=0\\
         (X'X + \Delta) \hat\beta_{\mathrm{RG}} &amp;=  X'Y
  \end{align*}\]</span> donc en prémultipliant par <span class="math inline">\((X'X-\Delta)^{-1}\)</span> nous obtenons <span class="math display">\[\begin{align*}
    \hat\beta_{\mathrm{RG}}=(X'X-\Delta)^{-1}X'Y.
  \end{align*}\]</span> En régression multiple le nombre de paramètres est <span class="math inline">\(p=\mathop{\mathrm{tr}}(P_{X})\)</span> avec <span class="math inline">\(P_{X}\)</span> la matrice de l’endomorphisme qui permet d’obtenir <span class="math inline">\(\hat Y\)</span> à partir de <span class="math inline">\(Y\)</span>. Dans cette régression ridge, nous avons que <span class="math display">\[\begin{align*}
    \hat Y_{\mathrm{RG}}&amp;=X\hat\beta_{\mathrm{RG}}=X(X'X-\Delta)^{-1}X'Y
  \end{align*}\]</span> donc la matrice de l’endomorphisme est ici <span class="math inline">\(X(X'X-\Delta)^{-1}X'\)</span> et le nombre équivalent de paramètres est <span class="math inline">\(\mathop{\mathrm{tr}}(X(X'X-\Delta)^{-1}X')\)</span>.</p>
</div>
<div id="exr-5-10" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 10 (IC pour la régression ridge) </strong></span>&nbsp;</p>
<ol type="1">
<li><p>Loi de <span class="math inline">\(\hat \beta\)</span> : <span class="math inline">\({\mathcal{N}}(\beta, \sigma^{2}(X'X)^{-1})\)</span> grâce au modèle et à <span class="math inline">\({\mathcal{H}}_3\)</span>.</p></li>
<li><p>Loi de $_{}() $. Comme <span class="math inline">\(\hat \beta_{\mathrm{ridge}}(\tilde\kappa)= (X'X-\tilde\kappa I)^{-1}X'Y\)</span> avec <span class="math inline">\(A=(X'X-\tilde\kappa I)^{-1}X'\)</span> qui est une matrice fixe. Avec <span class="math inline">\({\mathcal{H}}_{3}\)</span> et le modèle de régression multiple on a que <span class="math inline">\(Y\sim{\mathcal{N}}(X\beta, \sigma^{2}I)\)</span>.</p>
<p>Puisque <span class="math inline">\(Y\)</span> est un vecteur gaussien, il en est de même de <span class="math inline">\(\hat \beta_{\mathrm{ridge}}(\tilde\kappa)=AY\)</span>. Calculons son espérance <span class="math display">\[\begin{align*}
\mathbf E(\hat \beta_{\mathrm{ridge}}(\tilde\kappa))&amp;=\mathbf E(AY)=A\mathbf E(Y)=AX\beta\\
&amp;=(X'X-\tilde\kappa I)^{-1}X'X\beta
\end{align*}\]</span> et sa variance <span class="math display">\[\begin{align*}
\mathop{\mathrm{V}}(\hat \beta_{\mathrm{ridge}}(\tilde\kappa))&amp;=\mathop{\mathrm{V}}(AY)=A\mathop{\mathrm{V}}(Y)A'=A\sigma^{2}I A' = \sigma^{2} A A'\\
&amp;=\sigma^{2}(X'X-\tilde\kappa I)^{-1}X'X(X'X-\tilde\kappa I)^{-1}.
\end{align*}\]</span></p></li>
<li><p>Calculons le produit scalaire de <span class="math inline">\(Y-\hat Y_{\mathrm{ridge}}\)</span> et <span class="math inline">\(\hat Y_{MC}:\)</span> <span class="math display">\[\begin{align*}
&lt;Y-\hat Y_{\mathrm{ridge}};\hat Y_{MC}&gt;&amp;=&lt;Y-\hat Y_{MC} + \hat Y_{MC} -\hat Y_{\mathrm{ridge}};\hat Y_{MC}&gt;  \\
&amp; =  &lt;Y-\hat Y_{MC}; \hat Y_{MC}&gt; + &lt;   \hat Y_{MC} -\hat Y_{\mathrm{ridge}} ;  \hat Y_{MC}&gt;\\
&amp;= 0 + &lt;   \hat Y_{MC} -\hat Y_{\mathrm{ridge}} ;  \hat Y_{MC}&gt;
\end{align*}\]</span> Or <span class="math inline">\(\hat Y_{\mathrm{ridge}} = X\beta_{\mathrm{ridge}}(\tilde\kappa)\)</span> donc il appartient au sous espace vectoriel <span class="math inline">\(\Im(X)\)</span>, de même que <span class="math inline">\(\hat Y_{MC}=P_{X}Y\)</span>. Sauf si <span class="math inline">\(\tilde\kappa=0\)</span> on a que <span class="math inline">\(\hat Y_{\mathrm{ridge}}\neq \hat Y_{MC}\)</span> donc <span class="math inline">\(\hat Y_{MC} -\hat Y_{\mathrm{ridge}}\)</span> est un vecteur non nul de <span class="math inline">\(\Im(X)\)</span> et donc son produit scalaire avec <span class="math inline">\(\hat Y_{MC}\in \Im(X)\)</span> est non nul.</p></li>
<li><p>Il faut pouvoir démontrer l’indépendance de <span class="math inline">\(\hat\sigma_{\mathrm{ridge}}\)</span> et <span class="math inline">\(\hat \beta_{\mathrm{ridge}}\)</span>. Pour le théorème 5.1, on montre l’indépendance entre<span class="math inline">\(\hat \beta\)</span> et <span class="math inline">\(\hat \sigma\)</span> en considérant les 2 vecteurs <span class="math inline">\(\hat\beta\)</span> et <span class="math inline">\(\hat \varepsilon=(Y-\hat Y)\)</span>. Comme nous pouvons écrire <span class="math inline">\(\hat \beta=(X'X)^{-1}X'P_XY\)</span>, <span class="math inline">\(\hat \beta\)</span> est donc une fonction fixe (dépendante uniquement des <span class="math inline">\(X\)</span>) de <span class="math inline">\(P_XY\)</span>. De plus, <span class="math inline">\(\hat \varepsilon=P_{X^\perp}Y\)</span> est orthogonal à <span class="math inline">\(P_XY\)</span>. Ces 2 vecteurs suivent des lois normales et sont donc indépendants. Il en résulte que <span class="math inline">\(\hat \beta\)</span> et <span class="math inline">\(Y-\hat Y\)</span> sont indépendants et de même pour <span class="math inline">\(\hat \beta\)</span> et <span class="math inline">\(\hat \sigma\)</span>.</p>
<p>Ici, <span class="math inline">\(\hat\sigma_{\mathrm{ridge}}\)</span> est une fonction de <span class="math inline">\(Y-\hat Y_{\mathrm{ridge}}\)</span>. Le vecteur <span class="math inline">\(\hat\beta_{\mathrm{ridge}}=(X'X+\tilde\kappa I_p)^{-1}X'Y=(X'X+\tilde\kappa I_p)^{-1}X'P_XY\)</span> est une fonction fixe (<span class="math inline">\(\tilde \kappa\)</span> est considéré comme fixé) de <span class="math inline">\(P_XY\)</span>. Par contre, <span class="math inline">\(P_XY\)</span> n’est pas orthogonal à <span class="math inline">\((Y-\hat Y_{\mathrm{ridge}})\)</span>, comme nous l’avons montré, nous ne pouvons donc montrer l’indépendance de <span class="math inline">\(\hat\beta_{\mathrm{ridge}}\)</span> et <span class="math inline">\(\hat\sigma_{\mathrm{ridge}}\)</span>.</p>
<p>Une autre idée serait d’utiliser <span class="math inline">\(\hat\sigma\)</span> mais en général si l’on utilise la régression ridge c’est que l’on se doute que <span class="math inline">\(\hat Y\)</span> n’est pas un bon estimateur de <span class="math inline">\(X\beta\)</span> et donc <span class="math inline">\(\hat\sigma\)</span> qui est une fonction de <span class="math inline">\(Y-\hat Y\)</span> risque de ne pas être un bon estimateur de <span class="math inline">\(\sigma\)</span>. L’estimateur <span class="math inline">\(\hat\sigma\)</span> peut même être nul, ce qui pratiquement peut arriver quand <span class="math inline">\(p&gt;n\)</span>.</p></li>
<li><p>En général quand <span class="math inline">\(X\)</span> est fixe pour un bootstrap en régression on estime <span class="math inline">\(\hat \beta\)</span> puis on déduit les <span class="math inline">\(\{\hat \epsilon_{i}\}\)</span>. De cet ensemble sont tirés de manière équiprobable avec remise <span class="math inline">\(n\)</span> résidus <span class="math inline">\(\{\hat \epsilon_{i}^{*}\}\)</span>. Ces nouveaux résidus sont additionnés à <span class="math inline">\(X\beta\)</span> pour faire un nouveau vecteur <span class="math inline">\(Y^{*}\)</span> et avoir un échantillon bootstap <span class="math inline">\(Y^{*}, X\)</span>.</p>
<p>Ici l’estimation de <span class="math inline">\(\hat \beta\)</span> sera mauvaise (et c’est pour cela que l’on utilise la régression ridge) et plutôt que d’estimer de mauvais résidus nous allons retirer avec remise parmi les <span class="math inline">\(Y_{i}, X_{i.}\)</span> ce qui est la procédure adaptée au <span class="math inline">\(X\)</span> aléatoire mais ici nous avons peu de choix</p>
<p><strong>Entrées</strong> : <span class="math inline">\(\tilde \kappa\)</span> fixé, <span class="math inline">\(\alpha\)</span> fixé, <span class="math inline">\(B\)</span> choisi. <br> <strong>Sorties</strong> : IC, au niveau <span class="math inline">\(\alpha\)</span>, coordonnée par coordonnée de <span class="math inline">\(\beta\)</span>.</p>
<ol type="1">
<li>Estimer <span class="math inline">\(\beta_{\mathrm{ridge}}(\tilde \kappa)\)</span> .</li>
<li>En déduire <span class="math inline">\(\hat \varepsilon_{\mathrm{ridge}}=Y-X\hat \beta_{\mathrm{ridge}}\)</span>.</li>
<li>Pour <span class="math inline">\(k=1\)</span> à <span class="math inline">\(B\)</span>
<ul>
<li>tirer avec remise <span class="math inline">\(n\)</span> résidus estimés parmi les <span class="math inline">\(n\)</span> coordonnées de <span class="math inline">\(\hat \varepsilon_{\mathrm{ridge}}\)</span> ;</li>
<li>on note ces résidus (réunis dans 1 vecteur) <span class="math inline">\(\hat \varepsilon_{\mathrm{ridge}}^{(k)}\)</span> ;</li>
<li>construire 1 échantillon <span class="math inline">\(Y^{(k)}=X\beta_{\mathrm{ridge}}(\tilde \kappa)+\hat \varepsilon_{\mathrm{ridge}}^{(k)}\)</span> ;</li>
<li><span class="math inline">\(\tilde \kappa^{(k)} \leftarrow \tilde \kappa\)</span> ;</li>
<li>estimer le vecteur de paramètre <span class="math inline">\(\beta_{\mathrm{ridge}}^{(k)}(\tilde \kappa^{(k)})=(X'X+\tilde\kappa^{(k)} I_p)^{-1}X'Y^{(k)}\)</span> ;</li>
</ul></li>
<li>Pour <span class="math inline">\(j=1\)</span> à <span class="math inline">\(p\)</span>
<ul>
<li>calculer les quantiles empiriques de niveau <span class="math inline">\(\alpha/2\)</span> et <span class="math inline">\(1-\alpha/2\)</span> pour la coordonnée <span class="math inline">\(j\)</span>, sur tous les vecteurs <span class="math inline">\(\{\beta_{\mathrm{ridge}}^{(k)}(\tilde \kappa)\}\)</span> ;</li>
</ul></li>
</ol></li>
<li><p>L’algorithme est presque le même. Cependant comme <span class="math inline">\(\tilde \kappa\)</span> n’est pas fixé, pour estimer <span class="math inline">\(\beta_{\mathrm{ridge}}(\tilde \kappa)\)</span> il faut déterminer <span class="math inline">\(\tilde \kappa\)</span> par une méthode choisie. Ensuite, à chaque estimation de <span class="math inline">\(\beta_{\mathrm{ridge}}^{(k)}(\tilde \kappa^{(k)})\)</span>, il est nécessaire au préalable de déterminer <span class="math inline">\(\tilde \kappa^{(k)}\)</span> par la même méthode que celle utilisée pour déterminer <span class="math inline">\(\tilde \kappa\)</span>.</p></li>
</ol>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="../correction/chap4.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">4 Extensions : non-inversibilité et (ou) erreurs corrélées</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../correction/chap6.html" class="pagination-link">
        <span class="nav-page-text">6 Variables qualitatives : ANCOVA et ANOVA</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>