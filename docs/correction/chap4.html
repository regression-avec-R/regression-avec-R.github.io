<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Régression avec R - 4 Extensions : non-inversibilité et (ou) erreurs corrélées</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../correction/chap5.html" rel="next">
<link href="../correction/chap3.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Pas de résultats",
    "search-matching-documents-text": "documents trouvés",
    "search-copy-link-title": "Copier le lien vers la recherche",
    "search-hide-matches-text": "Cacher les correspondances additionnelles",
    "search-more-match-text": "correspondance de plus dans ce document",
    "search-more-matches-text": "correspondances de plus dans ce document",
    "search-clear-button-title": "Effacer",
    "search-detached-cancel-button-title": "Annuler",
    "search-submit-button-title": "Envoyer"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Correction des exercices</li><li class="breadcrumb-item"><a href="../correction/chap1.html">I Introduction au modèle linéaire</a></li><li class="breadcrumb-item"><a href="../correction/chap4.html">4 Extensions : non-inversibilité et (ou) erreurs corrélées</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Recherche" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Régression avec R</a> 
        <div class="sidebar-tools-main">
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Basculer en mode lecteur">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Recherche"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3ème édition</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../donnees.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Jeux de données</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Codes R</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">I Introduction au modèle linéaire</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 Régression simple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 La régression linéaire multiple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 Validation du modèle</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">II Inférence</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 Inférence dans le modèle Gaussien</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6 Variables qualitatives : ANCOVA et ANOVA</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false">
 <span class="menu-text">III Réduction de dimension</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7 Choix de variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8 Régularisation des moindres carrés : Ridge, Lasso et elastic net</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9 Régression sur composantes : PCR et PLS</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">10 Comparaison des différentes méthodes, étude de cas réels</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false">
 <span class="menu-text">IV Le modèle linéairé généralisé</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11 Régression logistique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12 Régression de Poisson</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13 Régularisation de la vraisemblance</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap15.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">15 Données déséquilibrées</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false">
 <span class="menu-text">V Introduction à la régression non paramétrique</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">16 Introduction à la régression spline</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../code/chap17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17 Estimateurs à noyau et <span class="math inline">\(k\)</span> plus proches voisins</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
 <span class="menu-text">Correction des exercices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true">
 <span class="menu-text">I Introduction au modèle linéaire</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" aria-expanded="true" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 La régression linéaire simple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 La régression linéaire multiple</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 Validation du modèle</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">4 Extensions : non-inversibilité et (ou) erreurs corrélées</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="false">
 <span class="menu-text">II Inférence</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 Inférence dans le modèle gaussien</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">6 Variables qualitatives : ANCOVA et ANOVA</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false">
 <span class="menu-text">III Réduction de dimension</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">7 Choix de variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">8 Régularisation des moindre carrés : Ridge, Lasso et elastic net</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">9 Régression sur composantes : PCR et PLS</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false">
 <span class="menu-text">IV Le modèle linéairé généralisé</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">11 Régression logistique</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">12 Régression de Poisson</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">13 Régularisation de la vraisemblance</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false">
 <span class="menu-text">V Introduction à la régression non paramétrique</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" aria-expanded="false" aria-label="Basculer la section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../correction/chap17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">17 Estimateurs à noyau et <span class="math inline">\(k\)</span> plus proches voisins</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
        
    </div>
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">4 Extensions : non-inversibilité et (ou) erreurs corrélées</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<div class="cell">

</div>
<div id="exr-4-1" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 1 (Questions de cours) </strong></span>B, B, B, A</p>
</div>
<div id="exr-4-2" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 2 (Corrélation multiple et hypothèse <span class="math inline">\(\mathcal{H}_1\)</span>) </strong></span>&nbsp;</p>
<ol type="1">
<li><p>Montrons que la moyenne empirique de <span class="math inline">\(X\hat \beta\)</span> vaut <span class="math inline">\(\bar Y\)</span>. Le vecteur moyenne est obtenu en projetant sur <span class="math inline">\(\mathbf{1}_n\)</span>. En effet, comme <span class="math display">\[\begin{eqnarray*}
P_{\mathbf{1}}&amp;=&amp;\mathbf{1}_n(\mathbf{1}_n'\mathbf{1}_n)^{-1}\mathbf{1}_n'=\frac{1}{n}\mathbf{1}_n\mathbf{1}_n',
\end{eqnarray*}\]</span> nous avons, pour une variable <span class="math inline">\(Z=(Z_1,\dotsc,Z_n)'\)</span>, <span class="math display">\[\begin{eqnarray*}
P_{\mathbf{1}}Z&amp;=&amp;=\frac{1}{n}\mathbf{1}_n \mathbf{1}_n'Z= \frac{1}{n}\mathbf{1}_n\sum_{i=1}^{n}{Z_i}=\bar Z\mathbf{1}_n.
\end{eqnarray*}\]</span> Comme <span class="math inline">\(\mathbf{1}_n\in\Im(X)\)</span>, nous avons <span class="math display">\[\begin{eqnarray*}
\bar Y&amp;=&amp;P_\mathbf{1}Y=P_\mathbf{1}P_XY=P_\mathbf{1}X\hat \beta,
\end{eqnarray*}\]</span> c’est-à-dire que la moyenne empirique de <span class="math inline">\(X\hat \beta\)</span> vaut <span class="math inline">\(\bar Y\)</span>.</p>
<p>Le coefficient de corrélation entre <span class="math inline">\(\hat Y\)</span> et <span class="math inline">\(Y\)</span> élevé au carré s’écrit donc <span class="math display">\[\begin{eqnarray*}
\rho^2(\hat Y,Y)&amp;=&amp;\frac{\langle \hat Y-\bar Y,Y-\bar Y\rangle^2}{\|\hat Y-\bar Y\|^2\|Y-\bar Y\|^2}\\
&amp;=&amp;\frac{\langle \hat Y-\bar Y,Y-\hat Y+\hat Y-\bar Y\rangle^2}{\|\hat Y-\bar Y\|^2\|Y-\bar Y\|^2}\\
&amp;=&amp;\Bigl\{\frac{\langle \hat Y-\bar Y,Y-\hat Y\rangle}{\|\hat Y-\bar Y\|\|Y-\bar Y\|}+\frac{\langle \hat Y-\bar Y,\hat Y-\bar Y\rangle}{\|\hat Y-\bar Y\|\|Y-\bar Y\|}\Bigl\}^2.
\end{eqnarray*}\]</span> Comme <span class="math inline">\((Y-\hat Y)\in\Im(X)^\perp\)</span> et que <span class="math inline">\((\hat Y-\bar Y)\in\Im(X)\)</span>, nous avons <span class="math inline">\(\langle \hat Y-\bar Y,Y-\hat Y\rangle=0\)</span> et donc <span class="math display">\[\begin{eqnarray*}
\rho^2(\hat Y,Y)&amp;=&amp;\frac{\|\hat Y-\bar Y\|^2 \|\hat Y-\bar Y\|^2}{\|\hat Y-\bar Y\|^2\|Y-\bar Y\|^2}=\mathop{\mathrm{R^2}}2.
\end{eqnarray*}\]</span></p></li>
<li><ol type="a">
<li><p>En effectuant le calcul nous trouvons que <span class="math inline">\(Y-2X_1+2X_2=3\eta\)</span>.</p></li>
<li><p>En calculant les normes carrées, nous avons <span class="math display">\[\begin{eqnarray*}
\|X_1\|^2&amp;=&amp;1^2+1^2+1^2=3,\\
\|X_2\|^2&amp;=&amp;1/2+1/2+2=3,\\
\|X_3\|^2&amp;=&amp;3/2+3/2=3.
\end{eqnarray*}\]</span> En calculant les produits scalaires, nous avons <span class="math display">\[\begin{eqnarray*}
\langle X_1,X_2\rangle&amp;=&amp;1\times 1/\sqrt{2}+ 1\times 1/\sqrt{2} +1\times (-\sqrt{2})
=\sqrt{2}-\sqrt{2}=0,\\
\langle X_1,\eta\rangle&amp;=&amp;\sqrt{3}/\sqrt{2}-\sqrt{3}/\sqrt{2}=0,\\
\langle X_2,\eta\rangle&amp;=&amp;1/\sqrt{2}\times\sqrt{3}/\sqrt{2}-1/\sqrt{2}\times\sqrt{3}/\sqrt{2}=0.
\end{eqnarray*}\]</span></p></li>
<li><p>La représentation graphique est :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="FIGURES/exo4-2.png" class="img-fluid figure-img" style="width:75.0%"></p>
</figure>
</div></li>
<li><p>Nous avons ici <span class="math inline">\(X_1\in\Im(X)\)</span>, <span class="math inline">\(X_2\in\Im(X)\)</span> et <span class="math inline">\(\eta\in\Im(X)^\perp\)</span>, ce qui permet de trouver <span class="math inline">\(\hat Y\)</span>~: <span class="math display">\[\begin{eqnarray*}
P_XY&amp;=&amp;P_X(2X_1-2X_2+3\eta)=2P_XX_1 -2P_XX_2+3P_X\eta=\\
&amp;=&amp;2X_1-2X_2=(2-\sqrt{2},2-\sqrt{2},2-2\sqrt{2})'.
\end{eqnarray*}\]</span></p></li>
<li><p>Puisque <span class="math inline">\(\mathbf{1}\)</span> fait partie des variables explicatives, nous avons <span class="math display">\[\begin{eqnarray*}
\rho(Y,\hat Y)&amp;=&amp;\frac{\langle Y-\bar Y,\hat Y-\bar Y\rangle}{\|\hat Y-\bar Y\|\|Y-\bar Y\|},
\end{eqnarray*}\]</span> ce qui est la définition du cosinus de l’angle entre <span class="math inline">\(\overrightarrow{\bar YY}\)</span> et <span class="math inline">\(\overrightarrow{\bar Y\hat Y}\)</span>.</p></li>
<li><p>Notons par <span class="math inline">\(Y_\alpha\)</span> le vecteur <span class="math inline">\(X\alpha\)</span>. Sa moyenne vaut <span class="math inline">\(\bar Y_\alpha\)</span>. Nous avons maintenant le cosinus de l’angle entre <span class="math inline">\(\overrightarrow{\bar YY}\)</span> et <span class="math inline">\(\overrightarrow{\bar Y_\alpha Y_\alpha}\)</span>. Graphiquement, la moyenne de <span class="math inline">\(Y_\alpha\)</span> est la projection sur <span class="math inline">\(X_1=\mathbf{1}_3\)</span>.</p></li>
<li><p>La représentation graphique nous permet de voir que l’angle entre <span class="math inline">\(\overrightarrow{\bar YY}\)</span> et <span class="math inline">\(\overrightarrow{\bar Y_\alpha Y_\alpha}\)</span> est le même que celui entre <span class="math inline">\(\overrightarrow{\bar YY}\)</span> et <span class="math inline">\(\overrightarrow{\bar Y\hat Y}\)</span>. L’angle est minimum (et le cosinus maximum) quand <span class="math inline">\(\alpha=\hat\beta\)</span> ou pour tout <span class="math inline">\(\alpha\)</span> tel que <span class="math inline">\(\overrightarrow{\bar Y_\alpha Y_\alpha}=k\overrightarrow{\bar Y\hat Y}\)</span> avec <span class="math inline">\(k&gt;0\)</span>.</p>
<p>Du fait de l’orthogonalité entre <span class="math inline">\(X_1\)</span> et <span class="math inline">\(X_2\)</span>, <span class="math inline">\(\overrightarrow{\bar Y_\alpha Y_\alpha}\)</span> est toujours colinéaire à <span class="math inline">\(\overrightarrow{\bar Y\hat Y}\)</span>, seul le signe change en fonction de l’orientation des vecteurs (même sens ou sens opposé).</p></li>
</ol></li>
<li><p>Comme <span class="math inline">\(\rho(X_j;X_k)=1\)</span> alors <span class="math inline">\(R(X_j;(\mathbf{1},X_j))=1\)</span> et donc puisque la constante fait partie du modèle <span class="math inline">\(R(X_j;X_{(j)})=1\)</span>. L’hypothèse <span class="math inline">\({\mathcal{H}}_1\)</span> n’est donc pas vérifiée.</p></li>
</ol>
</div>
<div id="exr-4-3" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 3 (EQM de la régression Ridge) </strong></span>&nbsp;</p>
<ol type="1">
<li><p>Les démonstrations figurent en page 77 : <span class="math display">\[\begin{eqnarray*}
B(\hat \beta_{ridge}) &amp;=&amp; -\kappa (X'X + \kappa I)^{-1} \beta,\\
V(\hat \beta_{\mathrm{ridge}})&amp;=&amp;\sigma^2(X'X + \kappa I)^{-1}X'X(X'X + \kappa I)^{-1}\\
\mathop{\mathrm{EQM}}(\hat \beta_{\mathrm{ridge}})&amp;=&amp;(X'X + \kappa I)^{-1}\left[\kappa^2\beta \beta'+\sigma^2(X'X) \right](X'X + \kappa I)^{-1}.
\end{eqnarray*}\]</span></p></li>
<li><p>Puisque <span class="math inline">\(X'X=P\mathop{\mathrm{diag}}(\lambda_i) P'\)</span>, nous avons <span class="math display">\[\begin{eqnarray*}
(X'X + \kappa I)&amp;=&amp;P\mathop{\mathrm{diag}}(\lambda_i) P'+ \kappa PP'=P\mathop{\mathrm{diag}}(\lambda_i+\kappa)P'.
\end{eqnarray*}\]</span> En se rappelant que <span class="math inline">\(P^{-1}=P'\)</span>, son inverse vaut <span class="math display">\[\begin{eqnarray*}
(X'X + \kappa I)^{-1}&amp;=&amp;P\mathop{\mathrm{diag}}(1/(\lambda_i+\kappa))P'.
\end{eqnarray*}\]</span> Nous avons donc <span class="math display">\[\begin{equation*}
\begin{split}
\mathop{\mathrm{EQM}}(\hat \beta_{\mathrm{ridge}})&amp;=P\mathop{\mathrm{diag}}(\frac{1}{\lambda_i+\kappa})P'\left[\kappa^2\beta \beta'+\sigma^2(X'X) \right]P\mathop{\mathrm{diag}}(\frac{1}{\lambda_i+\kappa})P'\\
&amp;=P\mathop{\mathrm{diag}}(\frac{1}{\lambda_i+\kappa})\left[\kappa^2(P'\beta\beta'P)+\sigma^2 I_p\right]\mathop{\mathrm{diag}}(\frac{1}{\lambda_i+\kappa})P'.
\end{split}
\end{equation*}\]</span> Nous en déduisons que sa trace vaut <span class="math display">\[\begin{equation*}
\begin{split}
\mathop{\mathrm{tr}}\left\{EQM(\hat \beta_{\mathrm{ridge}})\right\}&amp;=\mathop{\mathrm{tr}}\left\{\mathop{\mathrm{diag}}(\frac{1}{\lambda_i+\kappa})\left[\kappa^2(P'\beta\beta'P)+\sigma^2 I_p\right]\right.\\
&amp;\quad \left.\mathop{\mathrm{diag}}(\frac{1}{\lambda_i+\kappa})P'P\right\},
\end{split}
\end{equation*}\]</span> et, comme <span class="math inline">\(P'P=I_p\)</span>, nous avons alors <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{tr}}\left\{EQM(\hat \beta_{\mathrm{ridge}})\right\}
&amp;=&amp;\mathop{\mathrm{tr}}\left\{\left[\kappa^2(P'\beta\beta'P)+\sigma^2 I_p\right]\mathop{\mathrm{diag}}(\frac{1}{(\lambda_i+\kappa)^2})\right\}.
\end{eqnarray*}\]</span> Le <span class="math inline">\(i^e\)</span> élément de la diagonale de la matrice <span class="math inline">\(P'\beta\beta'P\)</span> vaut <span class="math inline">\([P'\beta]_i^2\)</span>. Celui de <span class="math inline">\(\left[\kappa^2(P'\beta\beta'P)+\sigma^2  I_p\right]\)</span> vaut <span class="math inline">\(\kappa^2[P'\beta]_i^2+\sigma^2\)</span> et celui de <span class="math display">\[\left[\kappa^2(P'\beta\beta'P)+\sigma^2
  I_p\right]\mathop{\mathrm{diag}}(\frac{1}{(\lambda_i+\kappa)^2})\]</span> vaut donc <span class="math display">\[\kappa^2[P'\beta]_i^2+\sigma^2/(\lambda_i+\kappa)^2.\]</span> On en déduit le résultat annoncé car la trace est la somme des éléments diagonaux d’une matrice.</p></li>
<li><p>L’estimateur des MC est non biaisé et son <span class="math inline">\(\mathop{\mathrm{EQM}}\)</span> vaut sa variance : <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{EQM}}(\hat \beta_{\mathrm{MC}})&amp;=&amp;\sigma^2(X'X)^{-1}.
\end{eqnarray*}\]</span> Nous avons alors <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{EQM}}(\hat \beta_{\mathrm{MC}})
\!&amp;=&amp;\!\sigma^2(X'X \!+\! \kappa I)^{-1}(X'X + \kappa I)(X'X)^{-1}\\
\!&amp;=&amp;\!\sigma^2(X'X \!+\! \kappa I)^{-1}(X'X(X'X)^{-1} + \kappa I(X'X)^{-1})\\
\!&amp;=&amp;\!\sigma^2(X'X \!+\! \kappa I)^{-1}(I\!+\!\kappa (X'X)^{-1})(X'X \!+\! \kappa I)(X'X \!+\! \kappa I)^{-1}\\
\!&amp;=&amp;\!\sigma^2(X'X \!+\! \kappa I)^{-1}(X'X\!+\!2 \kappa I \!+\! \kappa^2 (X'X)^{-1})(X'X \!+\! \kappa I)^{-1}.
\end{eqnarray*}\]</span></p></li>
<li><p>Le calcul de <span class="math inline">\(\Delta=\mathop{\mathrm{EQM}}(\hat \beta_{\mathrm{ridge}})- \mathop{\mathrm{EQM}}(\hat \beta_{\mathrm{MC}})\)</span> est immédiat en utilisant l’expression précédente de <span class="math inline">\(\mathop{\mathrm{EQM}}(\hat \beta_{\mathrm{MC}})\)</span> et celle rappelée en question 1.</p></li>
<li><p>En utilisant le théorème proposé avec <span class="math inline">\(A=(X'X + \kappa I)^{-1}\)</span> et <span class="math inline">\(B=(\sigma^2(2I_p+\kappa^2(X'X)^{-1})-\kappa\beta\beta')\)</span> nous obtenons le résultat demandé. Cette condition dépend de <span class="math inline">\(\beta\)</span> qui est inconnu, mais aussi de <span class="math inline">\(X\)</span>, c’est-à-dire des mesures obtenues.</p></li>
<li><p>Intéressons-nous à la matrice <span class="math inline">\(\gamma\gamma'\)</span>. Cette matrice est symétrique donc diagonalisable, de valeurs propres positives ou nulles. La somme de ses valeurs propres est égale à la trace de cette matrice <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{tr}}(\gamma\gamma')=\mathop{\mathrm{tr}}(\gamma'\gamma)=\gamma'\gamma.
\end{eqnarray*}\]</span> Montrons que cette matrice n’a qu’une seule valeur propre non nulle <span class="math inline">\(\gamma'\gamma\)</span>. Pour cela, considérons le vecteur <span class="math inline">\(\gamma\in\mathbb R^p\)</span> et montrons qu’il est vecteur propre de <span class="math inline">\(\gamma\gamma'\)</span> associé à la valeur propre <span class="math inline">\(\gamma'\gamma\)</span>~: <span class="math display">\[\begin{eqnarray*}
(\gamma\gamma')\gamma&amp;=&amp;\gamma(\gamma'\gamma)=(\gamma'\gamma)\gamma.
\end{eqnarray*}\]</span> Nous avons donc un vecteur propre de <span class="math inline">\(\gamma\gamma'\)</span> qui est <span class="math inline">\(\gamma\)</span> associé à la valeur propre <span class="math inline">\(\gamma'\gamma\)</span>. De plus, nous savons que la somme des valeurs propres positives ou nulles de <span class="math inline">\(\gamma\gamma'\)</span> vaut <span class="math inline">\(\gamma'\gamma\)</span>. Nous en déduisons que les <span class="math inline">\(p-1\)</span> valeurs propres restantes sont toutes nulles. Nous pouvons donc dire que la matrice <span class="math inline">\(\gamma\gamma'\)</span> se décompose comme <span class="math display">\[\begin{eqnarray*}
\gamma\gamma'&amp;=&amp;UDU',
\end{eqnarray*}\]</span> où <span class="math inline">\(U\)</span> est la matrice orthogonale des vecteurs propres normés à l’unité de <span class="math inline">\(\gamma\gamma'\)</span> et <span class="math inline">\(D=\mathop{\mathrm{diag}}(\gamma'\gamma,0,\dotsc,0)\)</span>. Nous avons donc <span class="math display">\[\begin{eqnarray*}
I_p-\gamma\gamma'&amp;=&amp;UU' - UDU'=U(\mathop{\mathrm{diag}}(1-\gamma'\gamma,1,\dotsc,1)U'.
\end{eqnarray*}\]</span> Les valeurs propres de <span class="math inline">\(I_p-\gamma\gamma'\)</span> sont donc <span class="math inline">\(1-\gamma'\gamma,1,\dotsc,1\)</span>, qui sont toutes positives ou nulles dès que <span class="math inline">\(\gamma'\gamma\le 1\)</span>.</p></li>
<li><p>Une condition pour que <span class="math inline">\(\sigma^2(2I_p-\kappa\beta\beta')\)</span> soit semi-définie positive est que <span class="math inline">\((\kappa\beta\beta')\le \sigma^2\)</span> (cf.&nbsp;question précédente) et donc <span class="math inline">\((\sigma^2(2I_p+\kappa^2(X'X)^{-1})-\kappa\beta\beta')\)</span> est alors la somme de 2 matrices semi-définies positives donc semi-définie positive. Cela implique qu’il s’agit d’une condition suffisante pour que <span class="math inline">\(\Delta\)</span> soit semi-définie positive.</p></li>
<li><p>Nous venons de montrer 2 conditions, l’une nécessaire et suffisante, l’autre suffisante, afin que <span class="math inline">\(\Delta\)</span> soit semi-définie positive. Cette assertion signifie que, quelle que soit la combinaison linéaire du vecteur de paramètre (par exemple une coordonnée), l’estimateur ridge est meilleur que celui des MC au sens de l’EQM. Cela signifie aussi que, si une de ces conditions est vérifiée, globalement au sens de la trace de l’EQM, l’estimateur ridge est meilleur que celui des MC. Au niveau des conditions, cela permet de trouver la valeur optimale de <span class="math inline">\(\kappa\)</span>. Malheureusement chacune des 2 conditions dépend de la valeur <span class="math inline">\(\beta\)</span> inconnue et donc n’est pas réellement utilisable en pratique. La condition suffisante procure une amélioration, dans le sens où elle ne dépend pas de <span class="math inline">\(X\)</span> donc de l’expérience. Le prix à payer est bien sûr qu’il s’agit seulement d’une condition suffisante et donc plus restrictive.</p></li>
</ol>
</div>
<div id="exr-4-4" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 4 (Régression pondérée) </strong></span>&nbsp;</p>
<ol type="1">
<li><p>Nous souhaitons minimiser <span class="math display">\[\begin{eqnarray*}
\sum_{i=1}^n \left(y_i-\sum_{j=1}^p \beta_j x_{ij}\right)^2 p_i,
\end{eqnarray*}\]</span> où <span class="math inline">\(p_i\)</span> est un réel positif. Nous pouvons écrire ce critère sous la forme suivante : <span class="math display">\[\begin{eqnarray*}
\sum_{i=1}^n \left(\sqrt{p_i}y_i-\sum_{j=1}^p \beta_j\sqrt{p_i} x_{ij}\right)^2
= \sum_{i=1}^n \left(y^\star_i-\sum_{j=1}^p \beta_jx_{ij}^\star\right)^2,
\end{eqnarray*}\]</span> où <span class="math inline">\(y^\star_i=\sqrt{p_i}y_i\)</span> et <span class="math inline">\(x_{ij}^\star = \sqrt{p_i} x_{ij}\)</span>.</p></li>
<li><p>Notons <span class="math inline">\(P^{1/2}\)</span> la matrice des poids qui vaut <span class="math inline">\(P^{1/2}=\mathop{\mathrm{diag}}(\sqrt{p_i})\)</span>. Ce dernier critère est un critère des MC avec comme observations <span class="math inline">\(Y^\star\)</span> et <span class="math inline">\(X^\star\)</span> où <span class="math inline">\(Y^\star = P^{1/2} Y\)</span> et <span class="math inline">\(X^\star = P^{1/2} X\)</span>. L’estimateur vaut alors <span class="math display">\[\begin{eqnarray*}
\hat \beta_{pond} &amp;=&amp; (X^{\star\prime}X^\star)^{-1}X^{\star\prime}Y^\star\\
&amp;=&amp; (X'PX)^{-1}X'PY.
\end{eqnarray*}\]</span></p></li>
<li><p>Lorsque nous avons la constante comme seule variable explicative, <span class="math inline">\(X=\mathbf{1}_n\)</span>, et nous avons alors <span class="math display">\[\begin{eqnarray*}
\hat \beta_{pond} &amp;=&amp;\frac{\sum p_i y_i}{\sum p_i}.
\end{eqnarray*}\]</span></p></li>
<li><p>Lorsque les poids sont constants, nous retrouvons, non plus une moyenne pondérée, mais la moyenne usuelle.</p></li>
</ol>
</div>
<div id="exr-4-5" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 5 (Gauss-Markov) </strong></span>L’estimateur des MC s’écrit <span class="math inline">\(\hat \beta_2 = \sum_{i=1}^n p_i y_i,\)</span> avec <span class="math inline">\(p_i=(x_i-\bar x)/\sum(x_i -\bar x)^2\)</span>. Considérons un autre estimateur <span class="math inline">\(\tilde{\beta_2}\)</span> linéaire en <span class="math inline">\(y_i\)</span> et sans biais, c’est-à-dire <span class="math display">\[\tilde{\beta_2} =\sum_{i=1}^n \lambda_i y_i.\]</span> Montrons que <span class="math inline">\(\sum \lambda_i=0\)</span> et <span class="math inline">\(\sum \lambda_i x_i=1\)</span>. L’égalité <span class="math inline">\(\mathbf E(\tilde{\beta_2}) = \beta_1 \sum \lambda_i + \beta_2 \sum \lambda_i x_i + \sum \lambda_i \mathbf E(\varepsilon_i)\)</span> est vraie pour tout <span class="math inline">\(\beta_2\)</span> et <span class="math inline">\(\tilde \beta_2\)</span> est sans biais donc <span class="math inline">\(\mathbf E(\tilde \beta_2)=\beta_2\)</span> pour tout <span class="math inline">\(\beta_2\)</span>, c’est-à-dire que <span class="math inline">\(\sum \lambda_i=0\)</span> et <span class="math inline">\(\sum \lambda_i x_i=1\)</span>.</p>
<p>Montrons que <span class="math inline">\(\mathop{\mathrm{V}}(\tilde{\beta_2}) \geq \mathop{\mathrm{V}}(\hat \beta_2)\)</span>. <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{V}}(\tilde{\beta_2}) = \mathop{\mathrm{V}}(\tilde{\beta_2}- \hat \beta_2 + \hat \beta_2)
=\mathop{\mathrm{V}}(\tilde{\beta_2}- \hat \beta_2)+\mathop{\mathrm{V}}(\hat \beta_2)+
2\mathop{\mathrm{Cov}}(\tilde{\beta_2}- \hat \beta_2,\hat \beta_2).
\end{eqnarray*}\]</span> <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{Cov}}(\tilde{\beta_2}- \hat \beta_2,\hat \beta_2)
\!=\!\mathop{\mathrm{Cov}}(\tilde{\beta_2},\hat \beta_2) -\mathop{\mathrm{V}}(-\hat \beta_2)
\!=\!\frac{\sigma^2\sum \lambda_i(x_i-\bar x)}{\sum (x_i-\bar x)^2} -
\frac{\sigma^2}{\sum (x_i-\bar x)^2}
\!=\!0,
\end{eqnarray*}\]</span> et donc <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{V}}(\tilde{\beta_2}) =
\mathop{\mathrm{V}}(\tilde{\beta_2}- \hat \beta_2)+\mathop{\mathrm{V}}(\hat \beta_2).
\end{eqnarray*}\]</span> Une variance est toujours positive et donc <span class="math display">\[\begin{eqnarray*}
\mathop{\mathrm{V}}(\tilde{\beta_2}) \geq \mathop{\mathrm{V}}(\hat \beta_2).
\end{eqnarray*}\]</span> Le résultat est démontré. On obtiendrait la même chose pour <span class="math inline">\(\hat \beta_1\)</span>.</p>
</div>
<div id="exr-4-6" class="theorem exercise">
<p><span class="theorem-title"><strong>Exercice 6 (Corrélation spatiale) </strong></span>&nbsp;</p>
<ol type="1">
<li><p>Écrivons pour la ligne/site <span class="math inline">\(i\)</span>: <span class="math display">\[\begin{align*}
Y_{i}&amp;=X_{i.}'\beta + \varepsilon_{i}
\end{align*}\]</span> et nous savons que <span class="math display">\[\begin{align*}
\varepsilon_{i}= \rho \sum_{i=1}^n M_{ij} \varepsilon_{j} + \eta_{i}
\end{align*}\]</span> Comme quand <span class="math inline">\(i=j\)</span> on a <span class="math inline">\(M_{ij}=0\)</span> on en déduit <span class="math display">\[\begin{eqnarray*}
\varepsilon_i=\rho\sum_{j\ne i,j=1}^{n}{M_{ij} \varepsilon_j} + \eta_i,
\end{eqnarray*}\]</span></p></li>
<li><p>Le site <span class="math inline">\(i\)</span> est expliqué par un modèle de type auto-régression par les autres sites. Le site est très dépendant des sites proches (fort <span class="math inline">\(M_{ij}\)</span>) et peu ou pas dépendant des autres sites (faible <span class="math inline">\(M_{ij}\)</span> ou valeur nulle).</p></li>
<li><p>On repart de <span class="math display">\[\begin{align*}
\varepsilon&amp;=\rho M \varepsilon +\eta\\
(I - \rho M)\varepsilon &amp;=\eta\\
\varepsilon&amp;=(I - \rho M)^{-1}\eta=A^{-1}\eta
\end{align*}\]</span></p></li>
<li><p>Comme <span class="math inline">\(\eta\)</span> est gaussien de moyenne nulle et de variance <span class="math inline">\(\sigma^{2}I\)</span> on a que <span class="math inline">\(\varepsilon\)</span> est gaussien de moyenne nulle et de variance <span class="math display">\[\begin{align*}
\mathop{\mathrm{V}}(\varepsilon) &amp;= \mathop{\mathrm{V}}(A^{-1}\eta) = A^{-1} \mathop{\mathrm{V}}(\eta) {A'}^{-1} =\sigma^{2}  A^{-1} {A'}^{-1}\\
&amp;=\sigma^{2}\Omega
\end{align*}\]</span></p></li>
<li></li>
<li><p>Pour la vraisemblance du modèle trouvons la loi de <span class="math inline">\(Y=X\beta + \varepsilon\)</span>. Comme <span class="math inline">\(\varepsilon\)</span> est gaussien de moyenne nulle et de variance <span class="math inline">\(\sigma^{2}\Omega\)</span> on a que <span class="math inline">\(Y\)</span> gaussien de moyenne <span class="math inline">\(X\beta\)</span> et de variance <span class="math inline">\(\sigma^{2}\Omega\)</span>. On a donc <span class="math display">\[\begin{align*}
L(Y,\beta,\sigma^2,\rho)&amp;=  \frac{1}{(2\pi)^{n/2}}\frac{1}{|\sigma^{2}\Omega|^{1/2}}
\exp\Bigl\{-\frac{1}{2\sigma^2}(Y-X\beta)'\Omega^{-1}(Y-X\beta)\Bigr\}
\end{align*}\]</span></p></li>
<li><p>La log-vraisemblance est <span class="math display">\[\begin{align*}
\mathcal{L}&amp;=-\frac{n}{2}\log (2\pi\sigma^{2}) - \frac{1}{2}\log|\Omega| - \frac{1}{2\sigma^2}(Y-X\beta)'\Omega^{-1}(Y-X\beta)
\end{align*}\]</span> La dérivée par rapport à <span class="math inline">\(\beta\)</span> est <span class="math display">\[\begin{align*}
\frac{\partial \mathcal{L}}{\partial\beta}&amp;=-\frac{1}{2\sigma^2}X'\Omega^{-1}(Y-X\beta)\\
\end{align*}\]</span> et en l’annulant on a <span class="math display">\[\begin{align*}
X'\Omega^{-1}Y=X'\Omega^{-1}X\hat\beta
\end{align*}\]</span> d’où <span id="eq-betahatcalif"><span class="math display">\[
\begin{eqnarray}
\hat \beta&amp;=&amp;(X'\hat \Omega^{-1}X)^{-1}X'\hat \Omega^{-1}Y\nonumber\\
&amp;=&amp;(X'\hat A'\hat AX)^{-1}X'\hat A'\hat AY.
\end{eqnarray}
\tag{1}\]</span></span></p></li>
<li><p>La dérivée par rapport à <span class="math inline">\(\sigma^2\)</span> est <span class="math display">\[\begin{align*}
\frac{\partial \mathcal{L}}{\partial\sigma^2}&amp;=-\frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}(Y-X\beta)'\Omega^{-1}(Y-X\beta)
\end{align*}\]</span> et en l’annulant on a <span id="eq-sigmahatcalif"><span class="math display">\[
\begin{align}
\hat \sigma^2&amp;=\frac{1}{n}(Y-X\hat \beta)'\hat \Omega^{-1} (Y-X\hat \beta)\nonumber\\
&amp;=\frac{1}{n}(Y-X\hat \beta)\hat A'\hat A (Y-X\hat \beta).
\end{align}
\tag{2}\]</span></span></p></li>
<li></li>
<li><p>Comme nous savons les valeurs de <span class="math inline">\(\hat \beta\)</span> comme fonction de <span class="math inline">\(\rho\)</span> (<a href="#eq-betahatcalif">équation&nbsp;1</a>) et de <span class="math inline">\(\hat \sigma^2\)</span> comme fonction de <span class="math inline">\(\rho\)</span> (<a href="#eq-sigmahatcalif">équation&nbsp;2</a>) il suffit de les remplacer dans <span class="math inline">\(-\mathcal{L}\)</span> et on obtient <span class="math display">\[\begin{eqnarray*}
    h(\hat\rho)\!&amp;=\!&amp;\!\frac{n}{2}\log Y'(I\!-\!X(X'\hat A'\hat AX)^{-1}X'\hat A'\hat A)'
\hat A'\hat A(I\!-\!X(X'\hat A'\hat AX)^{-1}X'\hat A'\hat A)Y \\
    &amp;&amp; \quad - \frac{1}{2}\log|\hat A'\hat A|^2
    \end{eqnarray*}\]</span></p></li>
</ol>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="../correction/chap3.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">3 Validation du modèle</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../correction/chap5.html" class="pagination-link">
        <span class="nav-page-text">5 Inférence dans le modèle gaussien</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>